<div class="content">
    <h1 class="title is-4">외국인AICC</h1>
    <p class="subtitle is-6">2024.06 ~ 2024.10</p>
    
    <div class="project-overview">
      <h2 class="title is-5">프로젝트 개요</h2>
      <p>감소하는 외국인 노동자 지원센터에 대응해 외국인 근로자를 위한 법률, 비자, 취업 AI 상담 서비스(채팅, 음성)</p>
    </div>

        <p class="modal-card-title">외국인AICC</p>
        <button class="delete" aria-label="close"></button>
        
        <div class="project-content">
          <p class="title">메인 포스터</p>
          <div class="poster-container">
            <div class="poster-pdf">
              <iframe src="img/foreignAICC-poster.pdf#toolbar=0&navpanes=0&scrollbar=0" width="300" height="200"></iframe>
            </div>
          </div>
          <div class="content">
            <p>제목: HelloWorld</p>
            <p>내용: 감소하는 외국인 노동자 지원센터에 대응해 외국인 근로자를 위한 법률, 비자, 취업 AI 상담 서비스(채팅, 음성)</p>
            <p>팀원: 5명</p>
            <p>수상: 서울시 새싹 해커톤 장려상(7위)</p>
            <ol>
              <li>외국인 노동자가 알고 싶은 것(법률, 비자 질문 등)에 대해 챗봇에 상담합니다.</li>
              <li>챗봇은 데이터를 기반으로 법적 정보, 예시, 구체적인 해결책을 제공합니다.</li>
              <li>추가 상담이 필요한 경우, 앱 내에서 직접 상담 일정을 잡을 수 있습니다.</li>
              <li>오프라인 상담의 노력을 줄이기 위해, 상담사에게 채팅 요약을 제공하여 프로세스를 더 원활하게 하는 데 도움을 줍니다.</li>
            </ol>  
          </div>
        </div>
        <hr/>
        
        <p class="title">수행 역할</p>
        <div class="content">
            <li>홈페이지에서 텍스트를 크롤링/전처리 후, 검색(Retrieval)을 위한 문서 청킹/임베딩을 수행하여 저장</li>
            <li>ElasticSearch를 활용한 DB 구축</li>
            <li>AWS EC2 인스턴스, Flask를 활용해 모델 배포</li>
            <li>Twilio를 활용해 다국어 음성 서비스 구현 및 배포</li>
        
            <br>

            <p class = "subtitle">주요 과제</p>
        
            <figure class="image is-4by2">
              <img src="img/foreignAICC-1.png">
            </figure>
            <p class = "subtitle">과제 1. 데이터 수집과 전처리</p>
              <p> 
                우리는 사용자의 질문을 크게 4가지 카테고리로 분류했습니다(법률, 비자, 상담사례, 채용).
                저는 각 카테고리별로 정부 웹사이트나 오픈 데이터 포털에서 텍스트를 수집하고, 구조화된 형식으로 변환했습니다.
              </p>
            <br>
            <p>데이터 예시</p>
            
            <pre id="json-display-1"></pre>
            <pre id="json-display-2"></pre>
        
            <script>
                const jsonData1 = {
                    "카테고리": "개인회생, 파산 및 면책 - 파산 및 면책",
                    "제목": "파산재단",
                    "질문": "파산재단이란 무엇인가요?",
                    "답변": "파산재단이란 파산선고 시 채무자가 보유한 모든 재산을 지칭합니다(채무자 회생 및 파산에 관한 법률 제382조 제1항)."
                };
        
                const jsonData2 = {
                    "사건명": "손해배상(기)",
                    "판결제목": "대법원 2021. 6. 10. 선고 2021다205490 판결",
                    "법원": "대법원",
                    "판결일": "2021-06-10",
                    "사건번호": "2021다205490",
                    "판결요지": {
                        "질문": "낙찰금액이 가상경쟁가격으로 하락한 경우, 그에 따라 관급자재 등의 분리발주 대상금액도 감소합니까?",
                        "답변": "부정",
                        "요약": "그 판시와 같은 이유를 들어, 낙찰금액이 가상경쟁가격으로 하락한 경우 그에 따라 관급자재 등의 분리발주 대상금액도 감소한다는 피고의 주장을 배척하였다.",
                        "핵심문장": "낙찰금액이 가상경쟁가격으로 하락한 경우, 관급자재 등의 분리발주 대상금액도 감소한다는 피고의 주장을 배척하였다."
                    },
                    "키워드": ["피고", "주장"],
                    "참조법령": "손해배상",
                    "참조판례": "",
                    "분류": "근로자 - 손해배상"
                };
        
                document.getElementById('json-display-1').textContent = JSON.stringify(jsonData1, null, 2);
                document.getElementById('json-display-2').textContent = JSON.stringify(jsonData2, null, 2);
            </script>
            <p> 
              모든 데이터 수집이 이루어진 후, 각 사전의 키 값을 모두 통합하여 청크 데이터를 구축했지만,
              위의 예시에서 날짜나 사건번호와 같이 중요도가 낮은 키 값은 제외하고 문서를 재구성했습니다.
            </p>
            <br>
        
            <p>전처리 과정</p>
            <figure class="image is-4by2">
              <img src="img/HelloWorld-llamadata.png">
            </figure>
            <p> 
              검색을 활용하기 위해서는 수집한 문서의 세심한 청킹 작업이 필요합니다.
              우리 모델(llama3)의 입력을 추정하기 위해, 수집한 문서를 llama3 tokenizer를 기반으로 토큰을 계산하고 시각화했습니다.
        
              모델링을 담당하는 동료가 1문서당 1000토큰 전후를 요구했습니다.
              따라서 수집한 데이터의 문서당 토큰 수를 128, 256, 512, 1024... 등의 입력 길이 단위로 시각화하고,
              1024토큰을 크게 초과하는 것에 한해 분할 작업을 수행했습니다.
              상담 사례와 같이 청킹시 의미가 퇴색될 우려가 있는 데이터에 대해서는, GPT api를 활용해 512 토큰 이하로 요약했습니다.
            </p>
        
            <!-- <figure class="image is-4by2">
              <img src="img/foreignAICC-1.png">
            </figure> -->
            <p class = "subtitle">과제 2. ElasticSearch를 활용한 DB 구축</p>
              <p> 
                Langchain과의 연동을 위해 ElasticSearch DB를 활용했습니다.
                앞서 512토큰 기준으로 분할된 chunk 데이터를 OpenAI embedding 모델을 활용해 임베딩하고, 저장했습니다.
              </p>
        
            <figure class="image is-4by2">
              <img src="img/foreignAICC-3.png">
            </figure>
            <p class = "subtitle">과제 3. AWS EC2 인스턴스, Flask를 활용해 모델 배포</p>
            <p> 
              Flask를 활용해 LLM 애플리케이션을 구축하고, 8B의 모델을 안정적으로 배포하기 위해 고용량의 인스턴스를 활용했습니다.
              주된 어려움은 Amazon 인스턴스에서 제공하는 다양한 ami들에서 파이썬 버전 및 모델 에플리케이션을 구성하는 라이브러리를 설치하는 것이었습니다.
              향후 Linux 시스템관리, 도커, 쉘 스크립팅 공부를 통해 부족함을 매꿔야 겠다고 생각했습니다.

            </p>
            <br>
            <p class = "subtitle">과제 4. Twilio를 활용한 음성 서비스 구현 및 배포</p>
              <p>
                Twilio는 클라우드 커뮤니케이션 플랫폼으로, 개발자들이 음성, 비디오, 메시징 등의 통신 기능을 애플리케이션에 쉽게 통합할 수 있게 해주는 서비스입니다.
                OpenAI API, Elasticsearch DB를 통해 RAG 기반 대화 시스템을 구축하고, 프롬프팅을 통해 다국어 기능을 추가했습니다.
                또한 맥락을 이해하고, 멀티턴을 수행하는 로직을 구성해 거부감을 줄이고, 자연스러운 대화를 지향했습니다.
                자세한 사항은 하래 깃허브를 참고해주세요!
              </p>
          </div>
          <p class="title">GitHub</p>
          <a href = "https://github.com/BambooStreet/HelloWorld_data">https://github.com/BambooStreet/HelloWorld_data</a>
        </div>

        
        <div class="tags">
          <span class="tag">python</span>
          <span class="tag">mysql</span>
          <span class="tag">langchain</span>
          <span class="tag">RAG</span>
        </div>
    </div>
</div>